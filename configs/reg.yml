optimizers:
#  scinol:
  scinol2:
#  cocob:
#  adam:
#  sgd:
#    - {learning_rate: 0.00001 }
#    - {learning_rate: 0.001 }
#  prescinol:
#  - {}
#  - {epsilon_scaled: 'd'}
#  - {epsilon_scaled: 'dt'}
#
#  adam:
#    - {learning_rate: 1.0 }
#    - {learning_rate: 0.1 }
#    - {learning_rate: 0.01 }
#    - {learning_rate: 0.001 }
#    - {learning_rate: 0.0001 }
#    - {learning_rate: 0.00001 }
#  adagrad:
#    - {learning_rate: 1.0 }
#    - {learning_rate: 0.1 }
#    - {learning_rate: 0.01 }
#    - {learning_rate: 0.001 }
#    - {learning_rate: 0.0001 }
#    - {learning_rate: 0.00001 }
#  rmsprop:
#    - {learning_rate: 1.0 }
#    - {learning_rate: 0.1 }
#    - {learning_rate: 0.01 }
#    - {learning_rate: 0.001 }
#    - {learning_rate: 0.0001 }
#    - {learning_rate: 0.00001 }
#  adadelt:
#    - {learning_rate: 1.0 }
#    - {learning_rate: 0.1 }
#    - {learning_rate: 0.01 }
#    - {learning_rate: 0.001 }
#    - {learning_rate: 0.0001 }
#    - {learning_rate: 0.00001 }
#  sgd:
#    - {learning_rate: 1.0 }
#    - {learning_rate: 0.1 }
#    - {learning_rate: 0.01 }
#    - {learning_rate: 0.001 }
#    - {learning_rate: 0.0001 }
#    - {learning_rate: 0.00001 }
#  nag:
#    - {learning_rate: 1.0 }
#    - {learning_rate: 0.1 }
#    - {learning_rate: 0.01 }
#    - {learning_rate: 0.001 }
#    - {learning_rate: 0.0001 }
#    - {learning_rate: 0.00001 }

models:
  LR:
    - {init0: True}


datasets:
  - UCI_CTScan


train_batchsize: 1
epochs: 5
times: 1
train_histograms: False
train_logs: True
no_tqdm: False
tblogdir: tb_logs_reg
loss: abs