optimizers:
  scinol:
  - {}
  - {beta: 1}
  - {epsilon_scaled: True}
  scinol2:
  - {}
  - {epsilon_scaled: True}
  scinola:
  scinol2a:
  scinolb:
  scinol2b:
  prescinol:
  - {}
  - {epsilon_scaled: 'd'}
  - {epsilon_scaled: 'dt'}
  cocob:
  prescinol2:
  adam:
    - {learning_rate: 1.0 }
    - {learning_rate: 0.1 }
    - {learning_rate: 0.01 }
    - {learning_rate: 0.001 }
    - {learning_rate: 0.0001 }
    - {learning_rate: 0.00001 }
  adagrad:
    - {learning_rate: 1.0 }
    - {learning_rate: 0.1 }
    - {learning_rate: 0.01 }
    - {learning_rate: 0.001 }
    - {learning_rate: 0.0001 }
    - {learning_rate: 0.00001 }
  rmsprop:
    - {learning_rate: 1.0 }
    - {learning_rate: 0.1 }
    - {learning_rate: 0.01 }
    - {learning_rate: 0.001 }
    - {learning_rate: 0.0001 }
    - {learning_rate: 0.00001 }
  adadelt:
    - {learning_rate: 1.0 }
    - {learning_rate: 0.1 }
    - {learning_rate: 0.01 }
    - {learning_rate: 0.001 }
    - {learning_rate: 0.0001 }
    - {learning_rate: 0.00001 }
  sgd:
    - {learning_rate: 1.0 }
    - {learning_rate: 0.1 }
    - {learning_rate: 0.01 }
    - {learning_rate: 0.001 }
    - {learning_rate: 0.0001 }
    - {learning_rate: 0.00001 }
  nag:
    - {learning_rate: 1.0 }
    - {learning_rate: 0.1 }
    - {learning_rate: 0.01 }
    - {learning_rate: 0.001 }
    - {learning_rate: 0.0001 }
    - {learning_rate: 0.00001 }

models:
  LR:
    - {init0: True}


datasets:
  - Mnist

train_batchsize: 1
epochs: 30
times: 1
train_histograms: False
train_logs: False
no_tqdm: True
tblogdir: tb_logs_linear