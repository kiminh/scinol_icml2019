optimizers:
  scinol:
  scinol2:
  cocob:
  prescinol:
  prescinol2:
  adam:
    - {learning_rate: 1.0 }
    - {learning_rate: 0.1 }
    - {learning_rate: 0.01 }
    - {learning_rate: 0.001 }
    - {learning_rate: 0.0001 }
  adagrad:
    - {learning_rate: 1.0 }
    - {learning_rate: 0.1 }
    - {learning_rate: 0.01 }
    - {learning_rate: 0.001 }
    - {learning_rate: 0.0001 }
  sgd:
    - {learning_rate: 1.0 }
    - {learning_rate: 0.1 }
    - {learning_rate: 0.01 }
    - {learning_rate: 0.001 }
    - {learning_rate: 0.0001 }
    - {learning_rate: 0.00001 }
  nag:
    - {learning_rate: 1.0 }
    - {learning_rate: 0.1 }
    - {learning_rate: 0.01 }
    - {learning_rate: 0.001 }
    - {learning_rate: 0.0001 }

models:
  LR:
    - {init0: True}

datasets:
  - UCI_Madelon



train_batchsize: 1
epochs: 60
times: 1
train_histograms: False
train_logs: False
no_tqdm: True